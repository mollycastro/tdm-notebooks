{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/CC_BY.png\"><br />\n",
    "\n",
    "Created on August 19, 2021 \n",
    "By Ted Lawless and [Nathan Kelber](http://nkelber.com) for [JSTOR Labs](https://labs.jstor.org/) under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/)<br />\n",
    "For questions/comments/improvements, email tdm@ithaka.org.<br />\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all sentences that match a word or phrase\n",
    "\n",
    "The Research Goal:\n",
    "\n",
    ">Identify any sentences in a dataset that match a word/phrase and output them to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before getting started\n",
    "\n",
    "This research question will require a Constellate dataset that contains the full-text of the document. You can create these in the [Constellate dataset builder](https://constellate.org/builder/) by selecting \"Full text only\" from the \"Download Availability\" filter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "First, we will import Python libraries to help us with our analysis. We will use:\n",
    "\n",
    "* The Pandas library for plotting and outputting our data to CSV\n",
    "* The [Natural Language Toolkit](https://www.nltk.org/) to parse the raw text into sentences\n",
    "* The [Constellate client](https://constellate.org/docs/constellate-client) to retrieve our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import constellate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also need to download the NLTK punkt tokenizer, which is required for parsing sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset and specify the matching text\n",
    "\n",
    "Download a dataset created in the Constellate application into the notebook environment.\n",
    "\n",
    "Add the dataset id that you are interested in retreiving as the `dataset_id` variable. This can be found on your [dashboard](https://constellate.org/dataset/dashboard) in the Constellate web application.\n",
    "\n",
    "If you do not have a dataset, here are two examples you could use:\n",
    "\n",
    "* `f477f1df-6cd5-c12e-844e-a04128e9b6e5`: All documents from JSTOR published in Proceedings of the American Philosophical Society from 1900 - 1930\n",
    "\n",
    "* `88a2bfb7-7196-0ca4-d545-d066ae8cc52c`: All documents from JSTOR published in The American Economic Review from 1910 - 1930 and limited to full text availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"88a2bfb7-7196-0ca4-d545-d066ae8cc52c\"\n",
    "\n",
    "dataset_file = constellate.get_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define the `matching_phrase` variable that you want to find in the text of the documents. This can be any string and a case insensitive match will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_phrase = \"inflation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the dataset into sentences\n",
    "\n",
    "1. Loop through all the documents in the dataset\n",
    "2. Read the `fullText` field (which is an array of page text) and parse sentences using nltk's sentence parser\n",
    "3. Check each sentence to see if it contains the matching phrase (case insensitive)\n",
    "4. Save matches to a Python list\n",
    "5. Record the following:\n",
    "    * document identifier\n",
    "    * publication year\n",
    "    * the page sequence number where the sentence was found\n",
    "    * the sentence sequence number within that page\n",
    "    * the text of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lower case our matching phrase and strip any whitespace\n",
    "matching_phrase = matching_phrase.lower().strip()\n",
    "\n",
    "# Define an empty list to store our matched sentences\n",
    "matched_sentences = []\n",
    "\n",
    "# Count our matches\n",
    "matched = 0\n",
    "\n",
    "# Count our loop iterations\n",
    "n = 0\n",
    "\n",
    "for document in constellate.dataset_reader(dataset_file):\n",
    "    publication_year = document[\"publicationYear\"]\n",
    "    for page_sequence, raw_page_text in enumerate(document.get(\"fullText\")):\n",
    "        # Replace all line breaks with spaces.\n",
    "        page = \" \".join(raw_page_text.split())\n",
    "        for sentence_sequence, sentence in enumerate(sent_tokenize(page)):\n",
    "            if matching_phrase in sentence.lower():\n",
    "                matched_sentences.append((document[\"id\"], publication_year, page_sequence, sentence_sequence, sentence))\n",
    "                matched += 1\n",
    "    n += 1\n",
    "    if (n % 100) == 0:\n",
    "       print(f\"{n} documents scanned\", document[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report number of matches\n",
    "print(f'{len(matched_sentences)} matching sentences found in your dataset.')\n",
    "\n",
    "# Preview the matched sentences\n",
    "# ID, year, page sequence, sentence sequence for page, actual matching sentence\n",
    "matched_sentences[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sentence dataframe\n",
    "\n",
    "Create a pandas DataFrame from the matched sentences. This makes it convenient to output as a CSV or analyze further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df = pd.DataFrame(matched_sentences, columns=[\"id\", \"publication_year\", \"page_seq\", \"sentence_seq\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot matching sentences over time\n",
    "Visualize the number of matches grouped by the year they occurred in a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df.groupby(\"publication_year\").size()\\\n",
    "  .plot(kind=\"bar\", title=\"Matching sentences over time\", xlabel=\"publication year\", ylabel=\"matching sentences\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output a csv file with the matching sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_file = f\"../data/{dataset_id}-sentences.csv\"\n",
    "\n",
    "sentence_df.to_csv(sent_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
